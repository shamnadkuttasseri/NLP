{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e95cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5df95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D:\\sofronics\\Datasets\\train (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bdf71ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech_count</th>\n",
       "      <th>offensive_language_count</th>\n",
       "      <th>neither_count</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech_count  offensive_language_count  neither_count  class  \\\n",
       "0      3                  0                         0              3      2   \n",
       "1      3                  0                         3              0      1   \n",
       "2      3                  0                         3              0      1   \n",
       "3      3                  0                         2              1      1   \n",
       "4      6                  0                         6              0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaa34bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet\n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
       "...                                                  ...\n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...\n",
       "24779  you've gone and broke the wrong heart baby, an...\n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...\n",
       "24781              youu got wild bitches tellin you lies\n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...\n",
       "\n",
       "[24783 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff=df.drop(['count','hate_speech_count','offensive_language_count','neither_count','class'],axis=1)\n",
    "dff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb0b84f",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5163374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35973fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized words in the first tweet: ['!', '!', '!', 'RT', '@', 'mayasolovely', ':', 'As', 'a', 'woman', 'you', 'should', \"n't\", 'complain', 'about', 'cleaning', 'up', 'your', 'house', '.', '&', 'amp', ';', 'as', 'a', 'man', 'you', 'should', 'always', 'take', 'the', 'trash', 'out', '...']\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'tweet' is the column containing text data\n",
    "tweets = dff['tweet'].tolist()\n",
    "\n",
    "# Tokenize each tweet\n",
    "tokenized_tweets = [word_tokenize(tweet) for tweet in tweets]\n",
    "\n",
    "# Example printing first tokenized tweet\n",
    "print(\"Tokenized words in the first tweet:\", tokenized_tweets[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeb20f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "\n",
      "                                       stemmed_tweet  \\\n",
      "0  ! ! ! rt @ mayasolov : as a woman you should n...   \n",
      "1  ! ! ! ! ! rt @ mleew17 : boy dat cold ... tyga...   \n",
      "2  ! ! ! ! ! ! ! rt @ urkindofbrand dawg ! ! ! ! ...   \n",
      "3  ! ! ! ! ! ! ! ! ! rt @ c_g_anderson : @ viva_b...   \n",
      "4  ! ! ! ! ! ! ! ! ! ! ! ! ! rt @ shenikarobert :...   \n",
      "\n",
      "                                 tokenized_sentences  \n",
      "0  [!, !!, RT @mayasolovely: As a woman you shoul...  \n",
      "1  [!, !!!!, RT @mleew17: boy dats cold...tyga dw...  \n",
      "2  [!, !!!!!!, RT @UrKindOfBrand Dawg!!!!, RT @80...  \n",
      "3  [!, !!!!!!!!, RT @C_G_Anderson: @viva_based sh...  \n",
      "4  [!, !!!!!!!!!!!!, RT @ShenikaRoberts: The shit...  \n"
     ]
    }
   ],
   "source": [
    "# Assuming 'tweet' is the column containing text data\n",
    "tweets = dff['tweet'].tolist()\n",
    "\n",
    "# Tokenize sentences within each tweet\n",
    "tokenized_sentences = []\n",
    "for tweet in tweets:\n",
    "    sentences = sent_tokenize(tweet)\n",
    "    tokenized_sentences.append(sentences)\n",
    "\n",
    "# Create a new column in the DataFrame to store tokenized sentences\n",
    "dff['tokenized_sentences'] = tokenized_sentences\n",
    "\n",
    "# Display the DataFrame\n",
    "print(dff.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35700d24",
   "metadata": {},
   "source": [
    "### Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a72a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6706402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "\n",
      "                                       stemmed_tweet  \n",
      "0  ! ! ! rt @ mayasolov : as a woman you should n...  \n",
      "1  ! ! ! ! ! rt @ mleew17 : boy dat cold ... tyga...  \n",
      "2  ! ! ! ! ! ! ! rt @ urkindofbrand dawg ! ! ! ! ...  \n",
      "3  ! ! ! ! ! ! ! ! ! rt @ c_g_anderson : @ viva_b...  \n",
      "4  ! ! ! ! ! ! ! ! ! ! ! ! ! rt @ shenikarobert :...  \n"
     ]
    }
   ],
   "source": [
    "#Assuming 'tweet' is the column containing text data\n",
    "tweets = dff['tweet'].tolist()\n",
    "\n",
    "# Initialize Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Stem each token in each tweet\n",
    "stemmed_tweets = []\n",
    "for tweet in tweets:\n",
    "    tokens = word_tokenize(tweet)\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    stemmed_tweet = ' '.join(stemmed_tokens)\n",
    "    stemmed_tweets.append(stemmed_tweet)\n",
    "\n",
    "# Create a new DataFrame column with the stemmed tweets\n",
    "dff['stemmed_tweet'] = stemmed_tweets\n",
    "\n",
    "# Display the DataFrame\n",
    "print(dff.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a5cbd",
   "metadata": {},
   "source": [
    "### Lemetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd4dece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "000009d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "\n",
      "                                       stemmed_tweet  \\\n",
      "0  ! ! ! rt @ mayasolov : as a woman you should n...   \n",
      "1  ! ! ! ! ! rt @ mleew17 : boy dat cold ... tyga...   \n",
      "2  ! ! ! ! ! ! ! rt @ urkindofbrand dawg ! ! ! ! ...   \n",
      "3  ! ! ! ! ! ! ! ! ! rt @ c_g_anderson : @ viva_b...   \n",
      "4  ! ! ! ! ! ! ! ! ! ! ! ! ! rt @ shenikarobert :...   \n",
      "\n",
      "                                 tokenized_sentences  \\\n",
      "0  [!, !!, RT @mayasolovely: As a woman you shoul...   \n",
      "1  [!, !!!!, RT @mleew17: boy dats cold...tyga dw...   \n",
      "2  [!, !!!!!!, RT @UrKindOfBrand Dawg!!!!, RT @80...   \n",
      "3  [!, !!!!!!!!, RT @C_G_Anderson: @viva_based sh...   \n",
      "4  [!, !!!!!!!!!!!!, RT @ShenikaRoberts: The shit...   \n",
      "\n",
      "                                    lemmatized_tweet  \n",
      "0  ! ! ! RT @ mayasolovely : As a woman you shoul...  \n",
      "1  ! ! ! ! ! RT @ mleew17 : boy dat cold ... tyga...  \n",
      "2  ! ! ! ! ! ! ! RT @ UrKindOfBrand Dawg ! ! ! ! ...  \n",
      "3  ! ! ! ! ! ! ! ! ! RT @ C_G_Anderson : @ viva_b...  \n",
      "4  ! ! ! ! ! ! ! ! ! ! ! ! ! RT @ ShenikaRoberts ...  \n"
     ]
    }
   ],
   "source": [
    "# Assuming 'tweet' is the column containing text data\n",
    "tweets = dff['tweet'].tolist()\n",
    "\n",
    "# Initialize WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize each word in each tweet\n",
    "lemmatized_tweets = []\n",
    "for tweet in tweets:\n",
    "    tokens = word_tokenize(tweet)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    lemmatized_tweet = ' '.join(lemmatized_tokens)\n",
    "    lemmatized_tweets.append(lemmatized_tweet)\n",
    "\n",
    "# Create a new DataFrame column with the lemmatized tweets\n",
    "dff['lemmatized_tweet'] = lemmatized_tweets\n",
    "\n",
    "# Display the DataFrame\n",
    "print(dff.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d0168",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f066d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20a40478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       00  000  0000000000000  003  007  007beardownjedi  007hertzrumble  \\\n",
      "0       0    0              0    0    0                0               0   \n",
      "1       0    0              0    0    0                0               0   \n",
      "2       0    0              0    0    0                0               0   \n",
      "3       0    0              0    0    0                0               0   \n",
      "4       0    0              0    0    0                0               0   \n",
      "...    ..  ...            ...  ...  ...              ...             ...   \n",
      "24778   0    0              0    0    0                0               0   \n",
      "24779   0    0              0    0    0                0               0   \n",
      "24780   0    0              0    0    0                0               0   \n",
      "24781   0    0              0    0    0                0               0   \n",
      "24782   0    0              0    0    0                0               0   \n",
      "\n",
      "       007m_h  00_jackie  00am  ...  zwnbhpdz8e  zwrimdzqnv  zwttsb9cc1  \\\n",
      "0           0          0     0  ...           0           0           0   \n",
      "1           0          0     0  ...           0           0           0   \n",
      "2           0          0     0  ...           0           0           0   \n",
      "3           0          0     0  ...           0           0           0   \n",
      "4           0          0     0  ...           0           0           0   \n",
      "...       ...        ...   ...  ...         ...         ...         ...   \n",
      "24778       0          0     0  ...           0           0           0   \n",
      "24779       0          0     0  ...           0           0           0   \n",
      "24780       0          0     0  ...           0           0           0   \n",
      "24781       0          0     0  ...           0           0           0   \n",
      "24782       0          0     0  ...           0           0           0   \n",
      "\n",
      "       zxuxfxpzi7  zycuodiwkz  zzachbarness  zzkagxivlu  zzzentropy  zzzquil  \\\n",
      "0               0           0             0           0           0        0   \n",
      "1               0           0             0           0           0        0   \n",
      "2               0           0             0           0           0        0   \n",
      "3               0           0             0           0           0        0   \n",
      "4               0           0             0           0           0        0   \n",
      "...           ...         ...           ...         ...         ...      ...   \n",
      "24778           0           0             0           0           0        0   \n",
      "24779           0           0             0           0           0        0   \n",
      "24780           0           0             0           0           0        0   \n",
      "24781           0           0             0           0           0        0   \n",
      "24782           0           0             0           0           0        0   \n",
      "\n",
      "       zzzzzz  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "24778       0  \n",
      "24779       0  \n",
      "24780       0  \n",
      "24781       0  \n",
      "24782       0  \n",
      "\n",
      "[24783 rows x 35852 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'tweet' is the column containing text data\n",
    "tweets = dff['tweet'].tolist()\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the tweets and transform the tweets into a BoW representation\n",
    "bow_matrix = vectorizer.fit_transform(tweets)\n",
    "\n",
    "# Convert the BoW matrix into a DataFrame for visualization\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the DataFrame\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640a267",
   "metadata": {},
   "source": [
    "### TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae195337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27b09885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        00  000  0000000000000  003  007  007beardownjedi  007hertzrumble  \\\n",
      "0      0.0  0.0            0.0  0.0  0.0              0.0             0.0   \n",
      "1      0.0  0.0            0.0  0.0  0.0              0.0             0.0   \n",
      "2      0.0  0.0            0.0  0.0  0.0              0.0             0.0   \n",
      "3      0.0  0.0            0.0  0.0  0.0              0.0             0.0   \n",
      "4      0.0  0.0            0.0  0.0  0.0              0.0             0.0   \n",
      "...    ...  ...            ...  ...  ...              ...             ...   \n",
      "24778  0.0  0.0            0.0  0.0  0.0              0.0             0.0   \n",
      "24779  0.0  0.0            0.0  0.0  0.0              0.0             0.0   \n",
      "24780  0.0  0.0            0.0  0.0  0.0              0.0             0.0   \n",
      "24781  0.0  0.0            0.0  0.0  0.0              0.0             0.0   \n",
      "24782  0.0  0.0            0.0  0.0  0.0              0.0             0.0   \n",
      "\n",
      "       007m_h  00_jackie  00am  ...  zwnbhpdz8e  zwrimdzqnv  zwttsb9cc1  \\\n",
      "0         0.0        0.0   0.0  ...         0.0         0.0         0.0   \n",
      "1         0.0        0.0   0.0  ...         0.0         0.0         0.0   \n",
      "2         0.0        0.0   0.0  ...         0.0         0.0         0.0   \n",
      "3         0.0        0.0   0.0  ...         0.0         0.0         0.0   \n",
      "4         0.0        0.0   0.0  ...         0.0         0.0         0.0   \n",
      "...       ...        ...   ...  ...         ...         ...         ...   \n",
      "24778     0.0        0.0   0.0  ...         0.0         0.0         0.0   \n",
      "24779     0.0        0.0   0.0  ...         0.0         0.0         0.0   \n",
      "24780     0.0        0.0   0.0  ...         0.0         0.0         0.0   \n",
      "24781     0.0        0.0   0.0  ...         0.0         0.0         0.0   \n",
      "24782     0.0        0.0   0.0  ...         0.0         0.0         0.0   \n",
      "\n",
      "       zxuxfxpzi7  zycuodiwkz  zzachbarness  zzkagxivlu  zzzentropy  zzzquil  \\\n",
      "0             0.0         0.0           0.0         0.0         0.0      0.0   \n",
      "1             0.0         0.0           0.0         0.0         0.0      0.0   \n",
      "2             0.0         0.0           0.0         0.0         0.0      0.0   \n",
      "3             0.0         0.0           0.0         0.0         0.0      0.0   \n",
      "4             0.0         0.0           0.0         0.0         0.0      0.0   \n",
      "...           ...         ...           ...         ...         ...      ...   \n",
      "24778         0.0         0.0           0.0         0.0         0.0      0.0   \n",
      "24779         0.0         0.0           0.0         0.0         0.0      0.0   \n",
      "24780         0.0         0.0           0.0         0.0         0.0      0.0   \n",
      "24781         0.0         0.0           0.0         0.0         0.0      0.0   \n",
      "24782         0.0         0.0           0.0         0.0         0.0      0.0   \n",
      "\n",
      "       zzzzzz  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         0.0  \n",
      "...       ...  \n",
      "24778     0.0  \n",
      "24779     0.0  \n",
      "24780     0.0  \n",
      "24781     0.0  \n",
      "24782     0.0  \n",
      "\n",
      "[24783 rows x 35852 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'tweet' is the column containing text data\n",
    "tweets = dff['tweet'].tolist()\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the tweets and transform the tweets into a TF-IDF representation\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(tweets)\n",
    "\n",
    "# Convert the TF-IDF matrix into a DataFrame for visualization\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the DataFrame\n",
    "print(tfidf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b61d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
